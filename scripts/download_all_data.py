#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡æ‰€æœ‰è‚¡ç¥¨å’ŒETFæ•°æ®æ‰¹é‡ä¸‹è½½è„šæœ¬
"""

import os
import sys
import time
from datetime import datetime
import pandas as pd
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.data_fetcher import AShareDataFetcher
from config.config import DATA_CONFIG

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_download.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def download_complete_dataset():
    """ä¸‹è½½å®Œæ•´çš„Aè‚¡æ•°æ®é›†"""
    print("ğŸš€ å¼€å§‹ä¸‹è½½Aè‚¡æ‰€æœ‰è‚¡ç¥¨å’ŒETFæ•°æ®")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®è·å–å™¨
    fetcher = AShareDataFetcher()
    
    # æ˜¾ç¤ºä¸‹è½½é…ç½®
    print(f"ğŸ“Š ä¸‹è½½é…ç½®:")
    print(f"   æ•°æ®è·¯å¾„: {DATA_CONFIG['data_path']}")
    print(f"   æ—¶é—´èŒƒå›´: {DATA_CONFIG['start_date']} è‡³ {DATA_CONFIG['end_date']}")
    print(f"   å¹¶è¡Œçº¿ç¨‹: {DATA_CONFIG.get('max_workers', 10)}")
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_path = DATA_CONFIG['data_path']
    if not os.path.exists(data_path):
        os.makedirs(data_path)
        print(f"âœ… åˆ›å»ºæ•°æ®ç›®å½•: {data_path}")
    
    # å¼€å§‹ä¸‹è½½
    start_time = time.time()
    
    try:
        print("\nğŸ“¥ å¼€å§‹æ‰¹é‡ä¸‹è½½æ•°æ®...")
        results = fetcher.download_all_data(max_workers=DATA_CONFIG.get('max_workers', 10))
        
        end_time = time.time()
        duration = end_time - start_time
        
        # æ˜¾ç¤ºä¸‹è½½ç»“æœ
        print("\n" + "=" * 60)
        print("           æ•°æ®ä¸‹è½½å®Œæˆ")
        print("=" * 60)
        
        print(f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡:")
        print(f"   æ€»è€—æ—¶: {duration:.2f} ç§’ ({duration/60:.1f} åˆ†é’Ÿ)")
        print(f"   æˆåŠŸè‚¡ç¥¨: {len(results['stocks'])} åª")
        print(f"   æˆåŠŸETF: {len(results['etfs'])} åª")
        print(f"   å¤±è´¥æ ‡çš„: {len(results['failed'])} ä¸ª")
        
        if results['failed']:
            print(f"\nâš ï¸  å¤±è´¥æ ‡çš„åˆ—è¡¨:")
            for symbol in results['failed'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"   - {symbol}")
            if len(results['failed']) > 10:
                print(f"   ... è¿˜æœ‰ {len(results['failed']) - 10} ä¸ªå¤±è´¥æ ‡çš„")
        
        # æ˜¾ç¤ºå¯ç”¨æ•°æ®
        available = fetcher.get_available_symbols()
        print(f"\nğŸ’¾ æœ¬åœ°æ•°æ®ç»Ÿè®¡:")
        print(f"   è‚¡ç¥¨æ•°æ®: {len(available['stocks'])} ä¸ªæ–‡ä»¶")
        print(f"   ETFæ•°æ®: {len(available['etfs'])} ä¸ªæ–‡ä»¶")
        print(f"   æŒ‡æ•°æ•°æ®: {len(available['index'])} ä¸ªæ–‡ä»¶")
        
        # ä¿å­˜ä¸‹è½½æ‘˜è¦
        summary_file = os.path.join(data_path, 'download_summary.txt')
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("Aè‚¡æ•°æ®ä¸‹è½½æ‘˜è¦\n")
            f.write("=" * 50 + "\n")
            f.write(f"ä¸‹è½½æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ•°æ®èŒƒå›´: {DATA_CONFIG['start_date']} è‡³ {DATA_CONFIG['end_date']}\n")
            f.write(f"æˆåŠŸè‚¡ç¥¨: {len(results['stocks'])} åª\n")
            f.write(f"æˆåŠŸETF: {len(results['etfs'])} åª\n")
            f.write(f"å¤±è´¥æ ‡çš„: {len(results['failed'])} ä¸ª\n")
            f.write(f"æ€»è€—æ—¶: {duration:.2f} ç§’\n\n")
            
            f.write("æˆåŠŸä¸‹è½½çš„è‚¡ç¥¨(å‰20åª):\n")
            for symbol in results['stocks'][:20]:
                f.write(f"  {symbol}\n")
            
            f.write("\næˆåŠŸä¸‹è½½çš„ETF(å‰20åª):\n")
            for symbol in results['etfs'][:20]:
                f.write(f"  {symbol}\n")
        
        print(f"\nğŸ“„ ä¸‹è½½æ‘˜è¦å·²ä¿å­˜è‡³: {summary_file}")
        
        return results
        
    except Exception as e:
        logger.error(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return None

def check_data_quality():
    """æ£€æŸ¥æ•°æ®è´¨é‡"""
    print("\n" + "=" * 60)
    print("           æ•°æ®è´¨é‡æ£€æŸ¥")
    print("=" * 60)
    
    fetcher = AShareDataFetcher()
    available = fetcher.get_available_symbols()
    
    # éšæœºæŠ½æ ·æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    sample_symbols = available['stocks'][:5] + available['etfs'][:3] + available['index'][:2]
    
    quality_report = []
    
    for symbol in sample_symbols:
        try:
            if symbol in available['stocks']:
                data = fetcher.load_data(symbol, 'stock')
                symbol_type = 'è‚¡ç¥¨'
            elif symbol in available['etfs']:
                data = fetcher.load_data(symbol, 'etf')
                symbol_type = 'ETF'
            else:
                data = fetcher.load_data(symbol, 'index')
                symbol_type = 'æŒ‡æ•°'
            
            if data is not None and not data.empty:
                quality_report.append({
                    'symbol': symbol,
                    'type': symbol_type,
                    'records': len(data),
                    'start_date': data.index[0].strftime('%Y-%m-%d'),
                    'end_date': data.index[-1].strftime('%Y-%m-%d'),
                    'status': 'âœ… æ­£å¸¸'
                })
            else:
                quality_report.append({
                    'symbol': symbol,
                    'type': symbol_type,
                    'records': 0,
                    'start_date': 'N/A',
                    'end_date': 'N/A',
                    'status': 'âŒ å¼‚å¸¸'
                })
                
        except Exception as e:
            quality_report.append({
                'symbol': symbol,
                'type': symbol_type,
                'records': 0,
                'start_date': 'N/A',
                'end_date': 'N/A',
                'status': f'âŒ é”™è¯¯: {str(e)}'
            })
    
    # æ˜¾ç¤ºè´¨é‡æŠ¥å‘Š
    print("\nğŸ” æ•°æ®è´¨é‡æŠ½æ ·æ£€æŸ¥:")
    for report in quality_report:
        print(f"   {report['symbol']} ({report['type']}): {report['status']}")
        if report['records'] > 0:
            print(f"       è®°å½•æ•°: {report['records']}, æ—¶é—´èŒƒå›´: {report['start_date']} è‡³ {report['end_date']}")
    
    return quality_report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Aè‚¡æ•°æ®æ‰¹é‡ä¸‹è½½å·¥å…·")
    print("=" * 60)
    
    # ä¸‹è½½æ•°æ®
    results = download_complete_dataset()
    
    if results:
        # æ£€æŸ¥æ•°æ®è´¨é‡
        quality_report = check_data_quality()
        
        # ç”Ÿæˆä½¿ç”¨å»ºè®®
        print("\n" + "=" * 60)
        print("           ä½¿ç”¨å»ºè®®")
        print("=" * 60)
        
        print("\nğŸ’¡ æ•°æ®ä½¿ç”¨è¯´æ˜:")
        print("   1. å›æµ‹æ—¶å¯ä½¿ç”¨ load_data() æ–¹æ³•åŠ è½½æœ¬åœ°æ•°æ®")
        print("   2. æ•°æ®æ–‡ä»¶è·¯å¾„: ./data/stocks/ å’Œ ./data/etfs/")
        print("   3. æ”¯æŒè‚¡ç¥¨ã€ETFã€æŒ‡æ•°ä¸‰ç§ç±»å‹æ•°æ®")
        print("   4. æ•°æ®å·²åŒ…å«å¤æƒä»·æ ¼ï¼Œå¯ç›´æ¥ç”¨äºå›æµ‹")
        
        print("\nğŸš€ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("   python run.py --mode backtest     # è¿è¡Œå›æµ‹")
        print("   python scripts/run_backtest.py   # è¿è¡Œå›æµ‹è„šæœ¬")
        
        print("\nâœ… æ•°æ®ä¸‹è½½å®Œæˆï¼Œå¯ä»¥å¼€å§‹å›æµ‹äº†ï¼")
    else:
        print("\nâŒ æ•°æ®ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæ•°æ®æºé…ç½®")

if __name__ == "__main__":
    main()